tutaj nic nowego, to co z labów 1...
> docker pull mongo:4.4.6        <=== ta wersja działa ze środowiskiem bez AVX
> docker build -t backend:latest -t backend:3.5.0 .
> docker build -t frontend:latest -t frontend:2.2.0 .

tutaj nic nowego, to co z labów 2...

przechodzimy do naszego namespaceu i uruchamiamy deployment, serwisy i inne zabawki na klastrze
(manifesty YAMLowe są w podfolderach w folderze controllers więc dodajemy -R):
> kubectl config set-context --current --namespace=fiszkilab2
> kubectl apply -R -f controllers/

żeby wejść na stronę trzeba mieć otwarty port forward
> kubectl port-forward deployment/backend-deployment 30080:8000

no i zaczynamy lab 3

poleceń za dużo nowych nie ma, ale na pewno przydatne były:

odpalenie shella w podzie:
> kubectl exec --stdin --tty <<nazwa poda>> -- /bin/bash

wyczyszczenie (prawie) wszystkiego:
> kubectl delete all --all
> kubectl delete pv --all
> kubectl delete pvc --all

oglądanie statusu podów na żywo (tutaj z filtracją po nazwie apki):
> kubectl get pods --watch -l app=fiszki-db


=== Procedury testowe, czyli skąd wiem że działa:
= Część na 3.0:

Uwaga!
Tutaj był akurat problem mały z tym, że backend zapisywał logi do katalogu /app bezpośrednio,
zaś zrobienie całego /app jako persistentVolume niezbyt mi się podobało (no bo w końcu mamy zapisywać logi a nie pliki wykonywalne pythona). W związku z tym zmieniłem lokalizację zapisu logów jako podfolder /app/log i dopiero pod ten katalog podpiąłem nasz wolumen.

1. wyświetlamy wszyskie pody
  > kubectl get pods
2. odpalamy shella na podzie backendu
  > kubectl exec --stdin --tty <<nazwa poda backendu>> -- /bin/bash
3. otwieramy plik z logami
  > cat /home/app/log/myapp.txt
  powinny być jakieś logi zapisane jeśli apka była używana
4. zabijamy poda backendu
  > kubectl delete pod <<nazwa poda backendu>>
5. wykonujemy kroki 1 2 i 3 ponownie ale tym razem wchodzimy do nowego poda.
  w pliku powinny pozostać logi sprzed zabicia poda

= Część na 3.5:

Tutaj sprawdzimy tylko czy persistentVolumeClaim i persistentVolume faktycznie są zbindowane i czy 
deployment ich używa.

1. wyświetlamy wszystkie claimy
  > kubectl get pvc
2. wyświetlamy szczegóły naszego claima
  > kubectl describe <<nazwa pvc dla backendu>>
  przykładowy poprawny output:
    Name:          fiszki-backend-pvc
    Namespace:     fiszkilab2
    StorageClass:  manual
    Status:        Bound                                <<== mówi że wolument i claim są połączone
    Volume:        fiszki-backend-pv
    Labels:        <none>
    Annotations:   pv.kubernetes.io/bind-completed: yes
                  pv.kubernetes.io/bound-by-controller: yes
    Finalizers:    [kubernetes.io/pvc-protection]
    Capacity:      1Gi
    Access Modes:  RWO
    VolumeMode:    Filesystem
    Used By:       backend-deployment-7c97f9c98d-qjc98  <<== mówi że deployment podpiął się pod wolumen
    Events:        <none>

= Część na 4.0:

Tutaj sprawdzimy trzy rzeczy: po pierwsze czy db faktycznie działa, po drugie czy działa persistence a po trzecie czy restart po zatrzymaniu działa poprawnie

Co do części pierwszej to sprawdzamy tak jak na poprzednich labach (z poziomu backendu).
Jeśli są problemy to warto wyczyścić log eventów kubernetesa:
> kubectl delete event --all
a potem wystartować ponownie db i sprawdzić w eventach co poszło nie tak:
> kubectl get events

Druga i trzecia część są trochę powiązane i można sprawdzić obie rzeczy na raz:

1. tworzymy jakieś wpisy do db z poziomu backendu a następnie pobieramy je i sprawdzamy czy się zgadza.
2. w osobnej konsoli włączamy obserwację podów db:
  > kubectl get pods --watch -l app=fiszki-db
3. zabijamy wszyskie pody db:
  > kubectl delete pod -l app=fiszki-db
4. na watchu patrzymy jak się restartują - pody wstają w kolejności 0,1,2,...,n
5. po restarcie ponownie pobieramy dane z poziomu backendu - powinny być identyczne co przed restartem

= Część na 4.5:

Tutaj po prostu uruchamiamy z nowymi ustawieniami i jeśli działa to się cieszymy